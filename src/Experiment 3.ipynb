{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from settings import *\n",
    "from glove import *\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from textblob import TextBlob\n",
    "from tweets_ops import *\n",
    "from url_helpers import analyze_url\n",
    "from matching import *\n",
    "from textstat.textstat import textstat\n",
    "import urllib, bs4\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "\n",
    "figures = conf['aux_dir']+'figure-eight/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv(cache_dir+'article_details_v6.tsv', sep='\\t')\n",
    "df7 = pd.read_csv(cache_dir+'article_details_v7.tsv', sep='\\t').fillna(0).drop('Alexa Rank', axis=1)\n",
    "df7['Author Signature'] = df6['authors'].apply(lambda x: len(eval(x)) != 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crispr = pd.read_csv(cache_dir+'crispr.tsv', sep='\\t').merge(df7, left_on='article', right_on='url')\n",
    "dfD = pd.read_csv(figures+'crispr-Dimitra.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert1'}).sort_values(by='article')\n",
    "dfJ = pd.read_csv(figures+'crispr-Jose.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert2'}).sort_values(by='article').drop('article', axis=1)\n",
    "df_exp_crispr = pd.concat([dfD,dfJ], axis=1)[['article', 'expert1', 'expert2']]\n",
    "df_exp_crispr.article = df_exp_crispr.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_exp_crispr['expert'] = (df_exp_crispr['expert1'] + df_exp_crispr['expert2'])/2\n",
    "df_crispr = df_crispr.merge(df_exp_crispr[['article', 'expert']])\n",
    "\n",
    "df_atc = pd.read_csv(cache_dir+'alc_tob_caf.tsv', sep='\\t').merge(df7, left_on='article', right_on='url')\n",
    "dfAn = pd.read_csv(figures+'tobacco-Andreu.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert1'}).sort_values(by='article')\n",
    "dfAi = pd.read_csv(figures+'tobacco-Aina.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert2'}).sort_values(by='article').drop('article', axis=1)\n",
    "df_exp_atc = pd.concat([dfAn,dfAi], axis=1)[['article', 'expert1', 'expert2']]\n",
    "df_exp_atc.article = df_exp_atc.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_exp_atc['expert'] = (df_exp_atc['expert1'] + df_exp_atc['expert2'])/2\n",
    "df_atc = df_atc.merge(df_exp_atc[['article', 'expert']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crispr = np.array(df_crispr.drop(['article', 'paper', 'title', 'url', 'expert'], axis=1).values, dtype=np.float32)\n",
    "y_crispr = df_crispr['expert'].values\n",
    "y_crispr = y_crispr.round().astype(int)\n",
    "\n",
    "X_atc = np.array(df_atc.drop(['article','paper1', 'title1', 'paper2', 'title2', 'paper3', 'title3', 'title', 'url', 'expert'], axis=1).values, dtype=np.float32)\n",
    "y_atc = df_atc['expert'].values\n",
    "y_atc = y_atc.round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 100\n",
    "m_dep = 100\n",
    "classifier = RandomForestClassifier(n_estimators=n_est, max_depth=m_dep, n_jobs=-1, random_state=42)\n",
    "\n",
    "classifier.fit(X_crispr, y_crispr)\n",
    "df_atc['scilens'] = classifier.predict(X_atc)\n",
    "\n",
    "# classifier.fit(X_atc, y_atc)\n",
    "# df_crispr['scilens'] = classifier.predict(X_crispr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atc[['article', 'scilens']].to_csv(cache_dir+'scilens_atc.tsv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
