{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from settings import *\n",
    "from urlAnalysis import create_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = create_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(urls)\n",
    "df.sort_values('in_degree', ascending=False)\n",
    "#df['netloc'] = df.apply(lambda r: get_url_domain(r['out_url']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(first_level_graph_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning\n",
    "df = df[~df['out_url'].isin(['http://TweetWithoutURL.org', 'http://HTTPError.org', 'http://TimeoutError.org'])]\n",
    "df['netloc'] = df.apply(lambda r: get_url_domain(r['out_url']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inst(netloc, inst):\n",
    "    for i in inst:\n",
    "        if i==netloc or i in netloc:\n",
    "            return i\n",
    "    return netloc\n",
    "\n",
    "df['netloc'] = df['netloc'].apply(lambda r: find_inst(r, inst['URL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = df.merge(inst, left_on='netloc', right_on='URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_roundlist = inst.groupby('Institution').size().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most popular Institutions')\n",
    "inst.groupby('Institution').mean()['popularity'].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.groupby('Institution').mean().plot.scatter(x='Score', y='popularity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = inst.groupby('Institution').mean()[['popularity', 'World Rank', 'National Rank', 'Alumni Employment', 'Publications', 'Influence', 'Citations', 'Broad Impact', 'Patents', 'Score']].corr()\n",
    "#sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)\n",
    "corr.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "countries['Name'] = countries['Name'].map(lambda n: n+'_user')\n",
    "countries['Location'] = countries['Location'].map(lambda n: n+'_inst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "B = nx.Graph()\n",
    "B.add_edges_from([(row['Name'], row['Location']) for _, row in countries.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "X, Y = bipartite.sets(B)\n",
    "pos = dict()\n",
    "pos.update( (n, (1, i)) for i, n in enumerate(X) ) # put nodes from X at x=1\n",
    "pos.update( (n, (2, i*4)) for i, n in enumerate(Y) ) # put nodes from Y at x=2\n",
    "nx.draw(B, pos=pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = pd.read_csv(repositoriesFile)\n",
    "repos['URL'] = repos['URL'].apply(lambda u: re.sub(r'^http://(www\\.)?', r'', u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repo(netloc, repos):\n",
    "    for i in repos:\n",
    "        if i==netloc or i in netloc:\n",
    "            return i\n",
    "    return netloc\n",
    "\n",
    "df['netloc'] = df['netloc'].apply(lambda r: find_repo(r, repos['URL']))\n",
    "repos = df.merge(repos, left_on='netloc', right_on='URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_round1 = repos['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos.groupby('Field').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['tweet'].isin(inst['tweet'].tolist()+repos['tweet'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(second_level_urls_file, 'w') as f:\n",
    "    #f.write('URL\\tnetloc\\n')\n",
    "    for u in df['out_url'].unique():\n",
    "        f.write(u+'\\t'+re.sub(r'^(http://)?(www\\.)?', r'', '{0.netloc}'.format(urlsplit(u)))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(second_level_graph_file, sep='\\t')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['netloc'] = df.apply(lambda r: get_url_domain(r['out_url']), axis=1)\n",
    "\n",
    "inst = pd.read_csv(institutionsFile, sep='\\t')\n",
    "inst['URL'] = inst['URL'].apply(lambda u: re.sub(r'^(www[0-9]?\\.)|(web\\.)', r'', u))\n",
    "def find_inst(netloc, inst):\n",
    "    for i in inst:\n",
    "        if i==netloc or i in netloc:\n",
    "            return i\n",
    "    return netloc\n",
    "\n",
    "df['netloc'] = df['netloc'].apply(lambda r: find_inst(r, inst['URL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = df.merge(inst, left_on='netloc', right_on='URL')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
