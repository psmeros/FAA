{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from settings import *\n",
    "from utils import human_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = corpusPath+'first_level_graph.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tweets:', human_format(len(df['tweet'].unique())))\n",
    "print('URLs:', human_format(len(df['out_url'])))\n",
    "print('Tweets without URL:', human_format(len(df['out_url'][df['out_url'].isin(['http://TweetWithoutURL.org'])])))\n",
    "print('HTTP Errors:', human_format(len(df['out_url'][df['out_url'].isin(['http://HTTPError.org'])])))\n",
    "print('Timeout Errors:', human_format(len(df['out_url'][df['out_url'].isin(['http://TimeoutError.org'])])))\n",
    "print('Unique URLs:', human_format(len(df['out_url'][~df['out_url'].isin(['http://TweetWithoutURL.org', 'http://HTTPError.org', 'http://TimeoutError.org'])].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only year\n",
    "df['date'] = df['date'].apply(lambda s : datetime.strptime(s, '%d.%m.%y %H:%M').year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()\n",
    "df1['out_url'] = df1['out_url'].apply(lambda u: u if u in ['http://TweetWithoutURL.org', 'http://HTTPError.org', 'http://TimeoutError.org'] else 'http://WorkingURL.org')\n",
    "df1[['tweet', 'date','out_url']].pivot_table(index='date', columns='out_url',aggfunc='count').T.reset_index(level=0, drop=True).T.fillna(1).plot(logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = df['out_url'][~df['out_url'].isin(['http://TweetWithoutURL.org', 'http://HTTPError.org', 'http://TimeoutError.org'])]\n",
    "from urllib.parse import urlsplit\n",
    "print('Unique Domains:', len(urls.apply(lambda u: '{0.netloc}/'.format(urlsplit(u))).unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in urls.apply(lambda u: urlsplit(u).netloc).unique():\n",
    "    if  u.endswith('.edu'):\n",
    "        print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = pd.read_csv(institutionsFile, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst['URL'] = inst['URL'].apply(lambda u: re.sub(r'^www[0-9]?\\.', r'', u).replace('web.', '', 1))\n",
    "inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
