{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from create_corpus import analyze_url\n",
    "\n",
    "scilens_dir = str(Path.home()) + '/Dropbox/scilens/www2019/'\n",
    "print_RMSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(scilens_dir + 'scilens_train.tsv', sep='\\t')\n",
    "for ind, name in zip(['Title Clickbaitness', 'Replies Stance'], ['clickbait_distro', 'stance_distro']):\n",
    "    sns.set(context='paper', style='white', color_codes=True, font_scale=2.5)\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    for r, q, c in zip([-1, 1], ['Low', 'High'], ['#CC4545', '#459FCC']):\n",
    "        ax = sns.kdeplot(df.loc[df['rate']==r][ind], label=q+' Quality Articles', color=c, shade= True, ax=ax)\n",
    "\n",
    "    plt.legend(loc='upper left', ncol=1, bbox_to_anchor=(0, 1.02))\n",
    "    plt.xlabel(ind)\n",
    "    plt.ylabel('Density')\n",
    "    \n",
    "    if name == 'stance_distro':\n",
    "        plt.xlim(1, -0.4)\n",
    "        loc, _ = plt.xticks()\n",
    "        loc = np.delete(loc, -0.4)\n",
    "        plt.xticks(loc, [round(1- 2*l,2) for l in loc])\n",
    "    sns.despine(left=True, bottom=True)\n",
    "    fig.savefig(scilens_dir+'figures/'+name+'.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_thr = .45\n",
    "\n",
    "df = pd.read_csv(scilens_dir+'atc-crowd.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'non-experts (w/o indicators)'})\n",
    "df = df[df._trust > trust_thr][['article', 'non-experts (w/o indicators)']]\n",
    "df.article = df.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_crowd = df.groupby('article').mean()\n",
    "\n",
    "df = pd.read_csv(scilens_dir+'atc-crowd-ind.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'non-experts (w/ indicators)'})\n",
    "df = df[df._trust > trust_thr][['article', 'non-experts (w/ indicators)']]\n",
    "df.article = df.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_crowd_ind = df.groupby('article').mean()\n",
    "\n",
    "df1 = pd.read_csv(scilens_dir+'atc-Andreu.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert1'}).sort_values(by='article')\n",
    "df2 = pd.read_csv(scilens_dir+'atc-Aina.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert2'}).sort_values(by='article').drop('article', axis=1)\n",
    "df_exp = pd.concat([df1,df2], axis=1)[['article', 'expert1', 'expert2']]\n",
    "df_exp.article = df_exp.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_exp['diff'] = abs(df_exp['expert1'] - df_exp['expert2'])\n",
    "df_exp['experts'] = (df_exp['expert1'] + df_exp['expert2'])/2\n",
    "df_exp = df_exp.set_index('article')\n",
    "\n",
    "\n",
    "df_sci = pd.read_csv(scilens_dir + 'atc_scilens.tsv', sep='\\t')\n",
    "df_sci = df_sci.set_index('article').rename(columns={'scilens':'SciLens'})\n",
    "\n",
    "df = df_crowd.join(df_exp).join(df_crowd_ind).join(df_sci).reset_index()\n",
    "\n",
    "if print_RMSE:\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==0]['non-experts (w/o indicators)'], df[df['diff']==0]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==0]['non-experts (w/ indicators)'], df[df['diff']==0]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==0]['SciLens'], df[df['diff']==0]['experts'])))\n",
    "    print()\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==1]['non-experts (w/o indicators)'], df[df['diff']==1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==1]['non-experts (w/ indicators)'], df[df['diff']==1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==1]['SciLens'], df[df['diff']==1]['experts'])))\n",
    "    print()\n",
    "    print(sqrt(mean_squared_error(df[df['diff']>1]['non-experts (w/o indicators)'], df[df['diff']>1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']>1]['non-experts (w/ indicators)'], df[df['diff']>1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']>1]['SciLens'], df[df['diff']>1]['experts'])))\n",
    "    print()\n",
    "    print(sqrt(mean_squared_error(df['non-experts (w/o indicators)'], df['experts'])))\n",
    "    print(sqrt(mean_squared_error(df['non-experts (w/ indicators)'], df['experts'])))\n",
    "    print(sqrt(mean_squared_error(df['SciLens'], df['experts'])))\n",
    "\n",
    "#plot    \n",
    "df = df.sort_values(by=['experts', 'diff'])\n",
    "l = df['article'].apply(lambda x: analyze_url(x)[0]).tolist()\n",
    "l = [{'winefolly.com':'Wine Folly (blog)',\n",
    " 'self.com':'Self (blog)',\n",
    " 'humanprogress.org':'Human Progress',\n",
    " 'vantagepointrecovery.com':'Vantage Point',\n",
    " 'marketwatch.com':'Market Watch',\n",
    " 'fortune.com':'Fortune',\n",
    " 'esquire.com':'Esquire',\n",
    " 'thisisinsider.com':'This is Insider',\n",
    " 'mentalfloss.com':'Mental Floss',\n",
    " 'uk.businessinsider.com':'Business Insider',\n",
    " 'healthline.com':'Health Line',\n",
    " 'illinoispolicy.org':'Illinois Policy',\n",
    " 'prevention.com':'Prevention',\n",
    " 'voanews.com':'VOA News',\n",
    " 'womenshealthmag.com':'Women\\'s Health',\n",
    " 'drugaddictionnow.com':'Drug Addiction Now',\n",
    " 'weforum.org':'WEForum',\n",
    " 'outsideonline.com':'Outside Online',\n",
    " 'nutritionadvance.com':'Nutrition Advance'}.get(o, o) for o in l]\n",
    "\n",
    "df['article'] = [v + ' (' + str(l[:i].count(v) + 1) + ')' if l.count(v) > 1 else v for i, v in enumerate(l)]\n",
    "#df['article'] = df.apply(lambda x: x['article']+'*' if x['diff']==0 else x['article']+'**' if x['diff']==1 else x['article']+'***', axis = 1)\n",
    "\n",
    "df = df[['article', 'non-experts (w/o indicators)', 'non-experts (w/ indicators)', 'experts', 'SciLens']].rename(columns={'non-experts (w/o indicators)': 'Non-Experts (No Indicators)', 'non-experts (w/ indicators)': 'Non-Experts (Indicators)', 'experts': 'Experts', 'SciLens': 'Automatic'})\n",
    "df = pd.melt(df, id_vars=['article'], var_name='Rated by', value_name='Quality').rename(columns={'article': 'Outlet'})\n",
    "df['Quality'] = df['Quality'] + 2\n",
    "\n",
    "df = df.sort_values(by=['Rated by', 'Quality'], ascending=[True,True])\n",
    "df = pd.concat([df[(df['Rated by'] == 'experts')],df[~(df['Rated by'] == 'experts')]])\n",
    "\n",
    "sns.set(context='paper', style='white', color_codes=True, font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(8,10))\n",
    "ax = sns.pointplot(hue='Rated by', x='Quality', y='Outlet', data=df[(df['Rated by'] == 'Experts')], markers='o', palette=['#9FCC45'], scale=3, ax=ax)\n",
    "plt.setp(ax.lines, zorder=100)\n",
    "plt.setp(ax.collections, zorder=100)\n",
    "ax = sns.barplot(hue='Rated by', x='Quality', y='Outlet', data=df[~(df['Rated by'] == 'Experts')], palette=['#CC4545', '#459FCC', '#2A617D'], ax=ax)\n",
    "ax.set_xticks(ticks=[0, 1, 2, 3, 4])\n",
    "ax.set_xticklabels(['Very Low', 'Low', 'Borderline', 'High', 'Very High'])\n",
    "#plt.xticks(rotation=90)\n",
    "plt.legend(loc='upper center', ncol=2, bbox_to_anchor=(0.5, 1.09))\n",
    "plt.ylabel('')\n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.savefig(scilens_dir+'figures/atc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(scilens_dir+'crispr-crowd.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'non-experts (w/o indicators)'})\n",
    "df = df[df._trust > trust_thr][['article', 'non-experts (w/o indicators)']]\n",
    "df.article = df.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_crowd = df.groupby('article').mean()\n",
    "\n",
    "df = pd.read_csv(scilens_dir+'crispr-crowd-ind.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'non-experts (w/ indicators)'})\n",
    "df = df[df._trust > trust_thr][['article', 'non-experts (w/ indicators)']]\n",
    "df.article = df.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_crowd_ind = df.groupby('article').mean()\n",
    "\n",
    "df1 = pd.read_csv(scilens_dir+'crispr-Dimitra.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert1'}).sort_values(by='article')\n",
    "df2 = pd.read_csv(scilens_dir+'crispr-Jose.csv').rename(columns={'how_do_you_rate_the_scientific_quality_of_this_article': 'expert2'}).sort_values(by='article').drop('article', axis=1)\n",
    "df_exp = pd.concat([df1,df2], axis=1)[['article', 'expert1', 'expert2']]\n",
    "df_exp.article = df_exp.article.apply(lambda x: x.replace('https://', 'http://'))\n",
    "df_exp['diff'] = abs(df_exp['expert1'] - df_exp['expert2'])\n",
    "df_exp['experts'] = (df_exp['expert1'] + df_exp['expert2'])/2\n",
    "df_exp = df_exp.set_index('article')\n",
    "\n",
    "\n",
    "df_sci = pd.read_csv(scilens_dir + 'crispr_scilens.tsv', sep='\\t')\n",
    "df_sci = df_sci.set_index('article').rename(columns={'scilens':'SciLens'})\n",
    "\n",
    "df = df_crowd.join(df_exp).join(df_crowd_ind).join(df_sci).reset_index()\n",
    "\n",
    "if print_RMSE:\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==0]['non-experts (w/o indicators)'], df[df['diff']==0]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==0]['non-experts (w/ indicators)'], df[df['diff']==0]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==0]['SciLens'], df[df['diff']==0]['experts'])))\n",
    "    print()\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==1]['non-experts (w/o indicators)'], df[df['diff']==1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==1]['non-experts (w/ indicators)'], df[df['diff']==1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']==1]['SciLens'], df[df['diff']==1]['experts'])))\n",
    "    print()\n",
    "    print(sqrt(mean_squared_error(df[df['diff']>1]['non-experts (w/o indicators)'], df[df['diff']>1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']>1]['non-experts (w/ indicators)'], df[df['diff']>1]['experts'])))\n",
    "    print(sqrt(mean_squared_error(df[df['diff']>1]['SciLens'], df[df['diff']>1]['experts'])))\n",
    "    print()\n",
    "    print(sqrt(mean_squared_error(df['non-experts (w/o indicators)'], df['experts'])))\n",
    "    print(sqrt(mean_squared_error(df['non-experts (w/ indicators)'], df['experts'])))\n",
    "    print(sqrt(mean_squared_error(df['SciLens'], df['experts'])))\n",
    "\n",
    "#plot\n",
    "df = df.sort_values(by=['experts', 'diff'])\n",
    "l = df['article'].apply(lambda x: analyze_url(x)[0]).tolist()\n",
    "l = [{'futurism.com':'Futurism', \n",
    "  'motherjones.com': 'Mother Jones',\n",
    "  'natureworldnews.com': 'Nature World News',\n",
    "  'dailyhealthpost.com': 'Daily Health Post',\n",
    "  'biotech-now.org': 'Biotech Now',\n",
    "  'fooddemocracynow.org': 'Food Democracy Now (blog)',\n",
    "  'huffingtonpost.com': 'Huffington Post',\n",
    "  'theverge.com': 'The Verge',\n",
    "  'genomealberta.ca': 'Genome Alberta',\n",
    "  'labiotech.eu': 'Labiotech',\n",
    "  'medicaldaily.com': 'Medical Daily',\n",
    "  'mashable.com': 'Mashable',\n",
    "  'newatlas.com': 'New Atlas',\n",
    "  'ibtimes.co.uk': 'IBTimes',\n",
    "  'shontavia.com': 'Shontavia Johnson (blog)',\n",
    "  'joshmitteldorf.scienceblog.com': 'Josh Mitteldorf (blog)',\n",
    "  'thebody.com': 'The Body',\n",
    " 'medium.com' : 'Twist Bioscience'}.get(o, o) for o in l]\n",
    "df['article'] = [v + ' (' + str(l[:i].count(v) + 1) + ')' if l.count(v) > 1 else v for i, v in enumerate(l)]\n",
    "#df['article'] = df.apply(lambda x: x['article']+'*' if x['diff']==0 else x['article']+'**' if x['diff']==1 else x['article']+'***', axis = 1)\n",
    "\n",
    "df = df[['article', 'non-experts (w/o indicators)', 'non-experts (w/ indicators)', 'experts', 'SciLens']].rename(columns={'non-experts (w/o indicators)': 'Non-Experts (No Indicators)', 'non-experts (w/ indicators)': 'Non-Experts (Indicators)', 'experts': 'Experts', 'SciLens': 'Automatic'})\n",
    "df = pd.melt(df, id_vars=['article'], var_name='Rated by', value_name='Quality').rename(columns={'article': 'Outlet'})\n",
    "df['Quality'] = df['Quality'] + 2\n",
    "\n",
    "df = df.sort_values(by=['Rated by', 'Quality'], ascending=[True,True])\n",
    "df = pd.concat([df[(df['Rated by'] == 'experts')],df[~(df['Rated by'] == 'experts')]])\n",
    "\n",
    "sns.set(context='paper', style='white', color_codes=True, font_scale=1.5)\n",
    "fig, ax = plt.subplots(figsize=(8,10))\n",
    "ax = sns.pointplot(hue='Rated by', x='Quality', y='Outlet', data=df[(df['Rated by'] == 'Experts')], markers='o', palette=['#9FCC45'], scale=3, ax=ax)\n",
    "plt.setp(ax.lines, zorder=100)\n",
    "plt.setp(ax.collections, zorder=100)\n",
    "ax = sns.barplot(hue='Rated by', x='Quality', y='Outlet', data=df[~(df['Rated by'] == 'Experts')], palette=['#CC4545', '#459FCC', '#2A617D'], ax=ax)\n",
    "ax.set_xticks(ticks=[0, 1, 2, 3, 4])\n",
    "ax.set_xticklabels(['Very Low', 'Low', 'Borderline', 'High', 'Very High'])\n",
    "#plt.xticks(rotation=90)\n",
    "plt.legend(loc='upper center', ncol=2, bbox_to_anchor=(0.5, 1.09))\n",
    "plt.ylabel('')\n",
    "sns.despine(left=True, bottom=True)\n",
    "fig.savefig(scilens_dir+'figures/crispr.pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
